{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "import numpy as np\n",
    "np.random.seed(400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('news.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>publish_date</th>\n",
       "      <th>headline_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>20030219</td>\n",
       "      <td>aba decides against community broadcasting lic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>20030219</td>\n",
       "      <td>act fire witnesses must be aware of defamation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>20030219</td>\n",
       "      <td>a g calls for infrastructure protection summit</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   publish_date                                      headline_text\n",
       "0      20030219  aba decides against community broadcasting lic...\n",
       "1      20030219     act fire witnesses must be aware of defamation\n",
       "2      20030219     a g calls for infrastructure protection summit"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "text=data[['headline_text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                       headline_text  index\n",
      "0  aba decides against community broadcasting lic...      0\n",
      "1     act fire witnesses must be aware of defamation      1\n",
      "2     a g calls for infrastructure protection summit      2\n",
      "3           air nz staff in aust strike for pay rise      3\n",
      "4      air nz strike to affect australian travellers      4\n"
     ]
    }
   ],
   "source": [
    "text['index'] = text.index\n",
    "documents = text\n",
    "print(documents.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'run'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WordNetLemmatizer().lemmatize('runs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Original Words</th>\n",
       "      <th>Lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>caresses</td>\n",
       "      <td>caress</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>flies</td>\n",
       "      <td>fly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>dies</td>\n",
       "      <td>die</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>mules</td>\n",
       "      <td>mules</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>denied</td>\n",
       "      <td>deny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>died</td>\n",
       "      <td>die</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>agreed</td>\n",
       "      <td>agree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>owned</td>\n",
       "      <td>own</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>humbled</td>\n",
       "      <td>humble</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>sized</td>\n",
       "      <td>size</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>meeting</td>\n",
       "      <td>meet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>stating</td>\n",
       "      <td>state</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>siezing</td>\n",
       "      <td>siezing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>itemization</td>\n",
       "      <td>itemization</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>sensational</td>\n",
       "      <td>sensational</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>traditional</td>\n",
       "      <td>traditional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>reference</td>\n",
       "      <td>reference</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>colonizer</td>\n",
       "      <td>colonizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>plotted</td>\n",
       "      <td>plot</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Original Words        Lemma\n",
       "0        caresses       caress\n",
       "1           flies          fly\n",
       "2            dies          die\n",
       "3           mules        mules\n",
       "4          denied         deny\n",
       "5            died          die\n",
       "6          agreed        agree\n",
       "7           owned          own\n",
       "8         humbled       humble\n",
       "9           sized         size\n",
       "10        meeting         meet\n",
       "11        stating        state\n",
       "12        siezing      siezing\n",
       "13    itemization  itemization\n",
       "14    sensational  sensational\n",
       "15    traditional  traditional\n",
       "16      reference    reference\n",
       "17      colonizer    colonizer\n",
       "18        plotted         plot"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer = SnowballStemmer(\"english\")\n",
    "original_words=['caresses', 'flies', 'dies', 'mules', 'denied','died', 'agreed', 'owned', \n",
    "           'humbled', 'sized','meeting', 'stating', 'siezing', 'itemization','sensational', \n",
    "           'traditional', 'reference', 'colonizer','plotted']\n",
    "\n",
    "singles= [WordNetLemmatizer().lemmatize(plural,pos='v') for plural in original_words]\n",
    "\n",
    "pd.DataFrame(data={'Original Words':original_words, 'Lemma':singles})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_stemming(text):\n",
    "    return stemmer.stem(WordNetLemmatizer().lemmatize(text,pos='v'))\n",
    "def preprocess(text):\n",
    "    result=[]\n",
    "    for token in gensim.utils.simple_preprocess(text):\n",
    "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token)>3:\n",
    "            result.append(lemmatize_stemming(token))\n",
    "            \n",
    "    return result        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original document: \n",
      "['act', 'fire', 'witnesses', 'must', 'be', 'aware', 'of', 'defamation']\n",
      "\n",
      "\n",
      " tokenized and lemmatized document: \n",
      "['wit', 'awar', 'defam']\n"
     ]
    }
   ],
   "source": [
    "doc_sample = documents[documents['index'] == 1].values[0][0]\n",
    "\n",
    "print('original document: ')\n",
    "words = []\n",
    "for word in doc_sample.split(' '):\n",
    "    words.append(word)\n",
    "print(words)\n",
    "print('\\n\\n tokenized and lemmatized document: ')\n",
    "print(preprocess(doc_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_docs = []\n",
    "\n",
    "for doc in documents['headline_text']:\n",
    "    processed_docs.append(preprocess(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(processed_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['decid', 'communiti', 'broadcast', 'licenc'], ['wit', 'awar', 'defam']]\n"
     ]
    }
   ],
   "source": [
    "print(processed_docs[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(6518 unique tokens: ['broadcast', 'communiti', 'decid', 'licenc', 'awar']...)\n"
     ]
    }
   ],
   "source": [
    "#bag of words on the data set\n",
    "dictionary = gensim.corpora.Dictionary(processed_docs)\n",
    "print (dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 broadcast\n",
      "1 communiti\n",
      "2 decid\n",
      "3 licenc\n",
      "4 awar\n",
      "5 defam\n",
      "6 wit\n",
      "7 call\n",
      "8 infrastructur\n",
      "9 protect\n",
      "10 summit\n",
      "11 aust\n",
      "12 rise\n",
      "13 staff\n",
      "14 strike\n",
      "15 affect\n",
      "16 australian\n",
      "17 travel\n",
      "18 ambiti\n",
      "19 jump\n",
      "20 olsson\n"
     ]
    }
   ],
   "source": [
    "count=0\n",
    "for k,v in dictionary.iteritems():\n",
    "    print (k, v)\n",
    "    count +=1\n",
    "    if count >20:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(723 unique tokens: ['communiti', 'decid', 'wit', 'call', 'protect']...)\n"
     ]
    }
   ],
   "source": [
    "dictionary.filter_extremes(no_below=15,no_above=0.1,keep_n=100000)\n",
    "print (dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 1)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_corpus = [dictionary.doc2bow(doc) for doc in processed_docs]\n",
    "bow_corpus[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word 3 (\"call\") appears 1 time.\n",
      "Word 4 (\"protect\") appears 1 time.\n",
      "Word 5 (\"summit\") appears 1 time.\n"
     ]
    }
   ],
   "source": [
    "document_num = 2\n",
    "bow_doc_x = bow_corpus[document_num]\n",
    "\n",
    "for i in range(len(bow_doc_x)):\n",
    "    print(\"Word {} (\\\"{}\\\") appears {} time.\".format(bow_doc_x[i][0], \n",
    "                                                     dictionary[bow_doc_x[i][0]],\n",
    "                                                     bow_doc_x[i][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora, models\n",
    "\n",
    "tfidf = models.TfidfModel(bow_corpus)\n",
    "corpus_tfidf = tfidf[bow_corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.6441604901095495), (1, 0.7648903601051755)]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "for doc in corpus_tfidf:\n",
    "    pprint(doc)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = gensim.models.LdaMulticore(bow_corpus, num_topics=10, id2word=dictionary, passes=2, workers=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: 0.024*\"hospit\" + 0.020*\"forc\" + 0.017*\"troop\" + 0.016*\"plan\" + 0.015*\"iraqi\" + 0.013*\"power\" + 0.013*\"arrest\" + 0.012*\"industri\" + 0.011*\"polic\" + 0.010*\"face\"\n",
      "Topic: 1 \n",
      "Words: 0.086*\"iraq\" + 0.020*\"say\" + 0.018*\"crash\" + 0.017*\"report\" + 0.016*\"saddam\" + 0.013*\"king\" + 0.013*\"iraqi\" + 0.013*\"season\" + 0.013*\"govt\" + 0.012*\"council\"\n",
      "Topic: 2 \n",
      "Words: 0.023*\"polic\" + 0.020*\"meet\" + 0.014*\"play\" + 0.014*\"critic\" + 0.013*\"miss\" + 0.012*\"continu\" + 0.012*\"injuri\" + 0.011*\"drug\" + 0.010*\"action\" + 0.009*\"consid\"\n",
      "Topic: 3 \n",
      "Words: 0.041*\"baghdad\" + 0.041*\"kill\" + 0.037*\"sar\" + 0.021*\"case\" + 0.017*\"troop\" + 0.014*\"australian\" + 0.014*\"injur\" + 0.013*\"report\" + 0.012*\"year\" + 0.011*\"airport\"\n",
      "Topic: 4 \n",
      "Words: 0.032*\"iraqi\" + 0.031*\"protest\" + 0.024*\"anti\" + 0.019*\"claim\" + 0.018*\"iraq\" + 0.017*\"dead\" + 0.015*\"suicid\" + 0.014*\"attack\" + 0.014*\"test\" + 0.012*\"jail\"\n",
      "Topic: 5 \n",
      "Words: 0.019*\"charg\" + 0.019*\"start\" + 0.018*\"water\" + 0.018*\"polic\" + 0.015*\"face\" + 0.012*\"court\" + 0.012*\"offer\" + 0.012*\"concern\" + 0.012*\"aust\" + 0.011*\"secur\"\n",
      "Topic: 6 \n",
      "Words: 0.031*\"govt\" + 0.026*\"urg\" + 0.026*\"charg\" + 0.016*\"group\" + 0.014*\"missil\" + 0.014*\"korea\" + 0.014*\"council\" + 0.012*\"servic\" + 0.012*\"north\" + 0.011*\"fire\"\n",
      "Topic: 7 \n",
      "Words: 0.028*\"world\" + 0.027*\"fund\" + 0.025*\"say\" + 0.020*\"open\" + 0.015*\"england\" + 0.014*\"polic\" + 0.013*\"welcom\" + 0.013*\"lose\" + 0.013*\"chief\" + 0.013*\"shoot\"\n",
      "Topic: 8 \n",
      "Words: 0.036*\"plan\" + 0.021*\"lead\" + 0.019*\"support\" + 0.019*\"iraq\" + 0.015*\"take\" + 0.015*\"inquiri\" + 0.013*\"strike\" + 0.013*\"communiti\" + 0.012*\"baghdad\" + 0.011*\"claim\"\n",
      "Topic: 9 \n",
      "Words: 0.028*\"govt\" + 0.020*\"warn\" + 0.018*\"minist\" + 0.017*\"court\" + 0.016*\"death\" + 0.014*\"begin\" + 0.013*\"miss\" + 0.013*\"baghdad\" + 0.012*\"face\" + 0.012*\"investig\"\n"
     ]
    }
   ],
   "source": [
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print('Topic: {} \\nWords: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model_tfidf = gensim.models.LdaMulticore(corpus_tfidf, num_topics=10, id2word=dictionary, passes=2, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 Word: 0.012*\"charg\" + 0.012*\"despit\" + 0.011*\"woman\" + 0.009*\"land\" + 0.009*\"death\" + 0.008*\"govt\" + 0.008*\"storm\" + 0.008*\"rais\" + 0.008*\"week\" + 0.008*\"fight\"\n",
      "Topic: 1 Word: 0.018*\"protest\" + 0.017*\"anti\" + 0.014*\"murder\" + 0.012*\"hop\" + 0.012*\"baghdad\" + 0.011*\"report\" + 0.009*\"king\" + 0.009*\"critic\" + 0.009*\"plan\" + 0.009*\"iraq\"\n",
      "Topic: 2 Word: 0.016*\"death\" + 0.012*\"council\" + 0.012*\"deni\" + 0.012*\"hous\" + 0.012*\"forc\" + 0.011*\"hold\" + 0.011*\"polic\" + 0.011*\"releas\" + 0.011*\"shark\" + 0.011*\"track\"\n",
      "Topic: 3 Word: 0.038*\"iraq\" + 0.017*\"warn\" + 0.012*\"protest\" + 0.011*\"port\" + 0.010*\"urg\" + 0.010*\"prepar\" + 0.010*\"restrict\" + 0.009*\"player\" + 0.009*\"water\" + 0.009*\"bush\"\n",
      "Topic: 4 Word: 0.017*\"boost\" + 0.013*\"doctor\" + 0.011*\"studi\" + 0.010*\"trade\" + 0.010*\"report\" + 0.009*\"expect\" + 0.009*\"island\" + 0.009*\"damag\" + 0.009*\"australia\" + 0.009*\"drop\"\n",
      "Topic: 5 Word: 0.028*\"baghdad\" + 0.017*\"kill\" + 0.014*\"plan\" + 0.012*\"face\" + 0.011*\"tour\" + 0.011*\"test\" + 0.010*\"concern\" + 0.009*\"saddam\" + 0.009*\"assault\" + 0.009*\"crash\"\n",
      "Topic: 6 Word: 0.015*\"lead\" + 0.014*\"world\" + 0.013*\"head\" + 0.012*\"meet\" + 0.011*\"injur\" + 0.010*\"secur\" + 0.010*\"claim\" + 0.010*\"push\" + 0.009*\"futur\" + 0.009*\"put\"\n",
      "Topic: 7 Word: 0.022*\"sar\" + 0.019*\"polic\" + 0.017*\"return\" + 0.017*\"open\" + 0.016*\"bomber\" + 0.015*\"take\" + 0.014*\"shoot\" + 0.013*\"iraq\" + 0.012*\"missil\" + 0.011*\"korea\"\n",
      "Topic: 8 Word: 0.020*\"win\" + 0.016*\"drought\" + 0.016*\"australia\" + 0.015*\"iraqi\" + 0.015*\"claim\" + 0.015*\"urg\" + 0.014*\"titl\" + 0.012*\"victori\" + 0.012*\"farmer\" + 0.011*\"accus\"\n",
      "Topic: 9 Word: 0.019*\"say\" + 0.018*\"iraqi\" + 0.014*\"marin\" + 0.012*\"court\" + 0.012*\"centr\" + 0.010*\"begin\" + 0.009*\"problem\" + 0.009*\"pakistan\" + 0.009*\"play\" + 0.008*\"bushfir\"\n"
     ]
    }
   ],
   "source": [
    "for idx, topic in lda_model_tfidf.print_topics(-1):\n",
    "    print('Topic: {} Word: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.38157644867897034\t Topic: 0.036*\"plan\" + 0.021*\"lead\" + 0.019*\"support\" + 0.019*\"iraq\" + 0.015*\"take\"\n",
      "Score: 0.3157622218132019\t Topic: 0.041*\"baghdad\" + 0.041*\"kill\" + 0.037*\"sar\" + 0.021*\"case\" + 0.017*\"troop\"\n",
      "Score: 0.2248576283454895\t Topic: 0.019*\"charg\" + 0.019*\"start\" + 0.018*\"water\" + 0.018*\"polic\" + 0.015*\"face\"\n",
      "Score: 0.01111773680895567\t Topic: 0.028*\"govt\" + 0.020*\"warn\" + 0.018*\"minist\" + 0.017*\"court\" + 0.016*\"death\"\n",
      "Score: 0.011116727255284786\t Topic: 0.031*\"govt\" + 0.026*\"urg\" + 0.026*\"charg\" + 0.016*\"group\" + 0.014*\"missil\"\n",
      "Score: 0.011115304194390774\t Topic: 0.032*\"iraqi\" + 0.031*\"protest\" + 0.024*\"anti\" + 0.019*\"claim\" + 0.018*\"iraq\"\n",
      "Score: 0.011114493012428284\t Topic: 0.086*\"iraq\" + 0.020*\"say\" + 0.018*\"crash\" + 0.017*\"report\" + 0.016*\"saddam\"\n",
      "Score: 0.011113994754850864\t Topic: 0.024*\"hospit\" + 0.020*\"forc\" + 0.017*\"troop\" + 0.016*\"plan\" + 0.015*\"iraqi\"\n",
      "Score: 0.011113286018371582\t Topic: 0.028*\"world\" + 0.027*\"fund\" + 0.025*\"say\" + 0.020*\"open\" + 0.015*\"england\"\n",
      "Score: 0.01111216377466917\t Topic: 0.023*\"polic\" + 0.020*\"meet\" + 0.014*\"play\" + 0.014*\"critic\" + 0.013*\"miss\"\n"
     ]
    }
   ],
   "source": [
    "unseen_document=\"\"\"It is my understanding that all True-Type fonts in Windows are loaded in\n",
    "prior to starting Windows - this makes getting into Windows quite slow if you\n",
    "have hundreds of them as I do.  First off, am I correct in this thinking -\n",
    "secondly, if that is the case - can you get Windows to ignore them on boot and\n",
    "maybe make something like a PIF file to load them only when you enter the\n",
    "applications that need fonts?  Any ideas?\"\"\"\n",
    "\n",
    "\n",
    "bow_vector = dictionary.doc2bow(preprocess(unseen_document))\n",
    "for index, score in sorted(lda_model[bow_vector], key=lambda tup: -1*tup[1]):\n",
    "    print(\"Score: {}\\t Topic: {}\".format(score, lda_model.print_topic(index, 5)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
